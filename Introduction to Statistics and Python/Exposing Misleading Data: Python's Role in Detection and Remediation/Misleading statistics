In what ways can data be misleading or misinterpreted, even when statistical concepts are applied correctly? How can Python be used to identify and address these issues? Provide examples from real-world situations.

 

Misleading statistics refer to data points, figures or visual representations that are inaccurate, false or manipulated to convey a distorted or biased message.

There are three main stages in the data analysis process where issues can occur:

    Collection: When you gather raw data
    Processing: When you analyze the raw data and determine its implications for your business
    Presentation: When you share the results of your analysis

Statistics can be misleading in a number of ways: selective bias, Unclear Linear vs. Logarithmic Scaling, A small sample size, erroneous correlations and causalities, use of manipulative graphics and visuals.

 

In this exercise, we will take a look at Neglected Sample Size.

 

Collecting data from too small a group can skew your survey and test results. Small samples do not adequately represent your target audience.

 

Example scenario:

Suppose two studies are conducted to assess the preferences of GRAND CANYON UNIVERSITY(GCU) students regarding university sports. The first study involves 100 students, the second 1,000. Comparing the results of the two studies can highlight the impact of sample size on the accuracy and reliability of the results.

References:

Hull, J. (2021). How to Spot Misleading Data Visualizations. Klipfolio. https://www.klipfolio.com/blog/how-to-spot-misleading-data

Harvard Business School Online. (n.d.). Bad Data Visualization: How to Avoid Common Mistakes. https://online.hbs.edu/blog/post/bad-data-visualization

Geckoboard.(2020). 5 sources of misleading statistics (and how they can jeopardize your company): https://www.geckoboard.com/blog/sources-of-misleading-statistics/
